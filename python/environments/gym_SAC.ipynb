{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537adf07",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "This notebook serves as an implementation of Soft Actor-Critic (SAC) on the custom-developed 2D navigation environment, titled ``Nav2D-v0``. The goal of this implementation is to quantify the performance of SAC in a simple 2D navigational  task, such that it can be used for incremental learning within subsequent environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d678bf",
   "metadata": {},
   "source": [
    "# **Imports**\n",
    "\n",
    "This section imports the necessary packages for this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium related packages:\n",
    "import gymnasium as gym\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "\n",
    "# import custom environments and wrappers:\n",
    "import nav2d\n",
    "from randomize_wrapper import RandomizeWrapper\n",
    "\n",
    "# import stablebaselines stuff:\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import Monitor\n",
    "\n",
    "# other necessary imports:\n",
    "from tqdm import tqdm\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758041ba",
   "metadata": {},
   "source": [
    "# **Environment Definition and Hyperparameters**\n",
    "\n",
    "This section defines and verifies the environment, defines the hyperparameters for the model, and creates a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the environment:\n",
    "env = gym.make(\"Nav2D-v0\")\n",
    "\n",
    "# check the environment:\n",
    "try: \n",
    "    check_env(env.unwrapped)\n",
    "    print(f\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has the following issues: \\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0b3c3",
   "metadata": {},
   "source": [
    "Define hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an environment:\n",
    "env = gym.make(\"Nav2D-v0\", max_episode_steps = 1000, render_mode = \"human\")\n",
    "\n",
    "# wrap in randomization wrapper:\n",
    "env = RandomizeWrapper(env = env, agent_freq = 5, goal_freq = 10, obstacle_freq = 10)\n",
    "\n",
    "# rescale to be within a custom bound of actions:\n",
    "# action_bounds = np.array([1, 0.0001, 2.0], dtype = np.float32)\n",
    "# env = RescaleAction(env, min_action = -action_bounds, max_action = action_bounds)\n",
    "\n",
    "# set a monitor:\n",
    "# env = Monitor(env, \"./monitor_logs\")\n",
    "\n",
    "# hyperparameters:\n",
    "policy = \"MlpPolicy\"\n",
    "gamma = 0.99\n",
    "learning_rate = 3e-4\n",
    "buffer_size = int(1e6)\n",
    "batch_size = 64\n",
    "tau = 5e-3\n",
    "ent_coef = \"auto_0.1\"\n",
    "train_freq = 1\n",
    "learning_starts = int(0)\n",
    "target_update_interval = 1\n",
    "gradient_steps = 4\n",
    "target_entropy = \"auto\"\n",
    "action_noise = None\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4f4f9",
   "metadata": {},
   "source": [
    "Create model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515351ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation using SB3:\n",
    "model = SAC(policy = policy, \n",
    "            env = env,\n",
    "            learning_rate = learning_rate,\n",
    "            buffer_size = buffer_size,\n",
    "            batch_size = batch_size,\n",
    "            tau = tau,\n",
    "            ent_coef = ent_coef,\n",
    "            train_freq = train_freq,\n",
    "            learning_starts = learning_starts,\n",
    "            target_update_interval = target_update_interval,\n",
    "            gradient_steps = gradient_steps,\n",
    "            target_entropy = target_entropy,\n",
    "            action_noise = action_noise, \n",
    "            verbose = verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc19b2",
   "metadata": {},
   "source": [
    "# **Train the model**\n",
    "\n",
    "Using the instantiated SB3 model, train on the ``Nav2D-v0`` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f494140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model.learn approach:\n",
    "model.learn(total_timesteps = 2000, log_interval = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e45918",
   "metadata": {},
   "source": [
    "# **Visualization**\n",
    "\n",
    "This section visualizes the learned policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # render settings:\n",
    "# width = 1280\n",
    "# height = 1280\n",
    "# default_camera_config = {\"azimuth\" : 90.0, \"elevation\" : -90.0, \"distance\" : 3, \"lookat\" : [0.0, 0.0, 0.0]}\n",
    "# camera_id = 2\n",
    "\n",
    "# DEFAULT_CAMERA = \"overhead_camera\"\n",
    "# ENABLE_FRAME = True\n",
    "# RENDER_EVERY_FRAME = True \n",
    "\n",
    "# # make a single environment:\n",
    "# env = gym.make(\"Nav2D-v0\", \n",
    "#                render_mode = \"human\", \n",
    "#                width = width, \n",
    "#                height = height,\n",
    "#                default_camera_config = default_camera_config, \n",
    "#                camera_id = camera_id, \n",
    "#                max_episode_steps = 500)\n",
    "\n",
    "# if DEFAULT_CAMERA==\"overhead_camera\": pyautogui.press('tab')\n",
    "# if ENABLE_FRAME: pyautogui.press('e') \n",
    "# if not RENDER_EVERY_FRAME: pyautogui.press('d') \n",
    "\n",
    "# # for every test episode:\n",
    "# for eps in range(10):\n",
    "#     obs, _ = env.reset(agent_randomize = True, obstacle_randomize = True)\n",
    "#     done = False\n",
    "\n",
    "#     # while not done:\n",
    "#     while not done:\n",
    "#         action, _ = model.predict(obs, deterministic = True)\n",
    "#         nobs, reward, term, trunc, _ = env.step(action)\n",
    "#         done = term or trunc\n",
    "\n",
    "#         # advance observation, reset if not:\n",
    "#         obs = nobs if not done else env.reset()\n",
    "        \n",
    "#         # render for user:\n",
    "#         env.render()\n",
    "\n",
    "# # close when done:\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
